# Pre-week - Sentence Constructor


## Limitations

1. I only have free tier access to online AI Assistants, and will have to experiement with free-tier capabilities and a Ollama + OpenWebUI local setup.

2. My Japanese knowledge is extremely basic and limited to spoken, even though I can read some Kanji.

## Questions

1. How well can free-tier AI Assistants perform? 

2. Will I be able to complete the exercise in a single session with free tier? Or will I hit usage limits?

2. What would be the performance difference between different model families, e.g. Llama vs Qwen vs Deepseek?

3. What would be the performance difference between model sizes, e.g. 3B vs 8B vs 16B?

4. Is my setup sufficiant to run 16B models? What about 32B models?

5. Will I be able to assess the quality of the output given my (lack of) Japanese language skills? Will I need to pivot to Chinese instead?

## Discoveries

1. While I cannot read kana and therefore am not able to complete the sentence construction exercise in full Japanese, if I use romanji exclusively, it just may work!